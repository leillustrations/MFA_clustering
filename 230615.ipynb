{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install pandas\n",
        "%pip install pygal\n",
        "%pip install cairosvg\n",
        "%pip install matplotlib\n",
        "%pip install seaborn\n",
        "%pip install sklearn\n",
        "%pip install scikit-learn"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIkA7g-vj5Qy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.preprocessing import MinMaxScaler\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ogmAQJhrpfj8"
      },
      "source": [
        "## Import and load spreadsheet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5HIkQPwgxFQ"
      },
      "outputs": [],
      "source": [
        "data = '230607data.csv'\n",
        "# headers = data.pop(0)\n",
        "df = pd.read_csv(data, header=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pj2LULpsi74z"
      },
      "outputs": [],
      "source": [
        "demographic_columns = ['po _1','gender','residence','country','vegetarian','vegan']\n",
        "cat_columns = ['Caring About Animals', 'Support for Institutional Welfare Solutions','Perceptions of Meat & Plant-Based Food','Perceptions of Intersecting Issues','Support for Farmed Animal Advocacy','Consumption of Animal Products (Self-Reported)']\n",
        "cat_columns_reorder = ['Caring About Animals', 'Support for Institutional Welfare Solutions',\n",
        "               'Knowledge about Farmed Animal Conditions', 'Consumption of Animal Products (Self-Reported)',\n",
        "               'Perceptions of Meat & Plant-Based Food','Support for Farmed Animal Advocacy',\n",
        "               'Perceptions of Intersecting Issues']\n",
        "df = df.reindex(columns=demographic_columns+cat_columns_reorder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sIVoYSi29JV"
      },
      "outputs": [],
      "source": [
        "for col in cat_columns_reorder:\n",
        "  df[col] = pd.to_numeric(df[col])\n",
        "\n",
        "# for col in demographic_columns:\n",
        "  # df[col] = pd.to_numeric(df[col])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploratory Analysis"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Demographic data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def barplot(col):\n",
        "  \n",
        "  mean = df.groupby(col)[columns_to_cluster].mean()\n",
        "  std = df.groupby(col)[columns_to_cluster].std()\n",
        "  ax = mean.plot(kind='bar')\n",
        "  ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Histograms of cat_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for col in cat_columns_reorder:\n",
        "    plt.figure()\n",
        "    sns.histplot(df[col],kde=False)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUENuuEIwJyc",
        "outputId": "8fe7156b-ee0f-4e1a-9bee-3a78e131046f"
      },
      "outputs": [],
      "source": [
        "# Data Exploration\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "print(df.describe())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Paired scatterplots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_values = [float(row[col_1]) for row in data[1:]]\n",
        "y_values = [float(row[col_2]) for row in data[1:]]\n",
        "\n",
        "# mean and std\n",
        "x_mean, y_mean = np.mean(x_values), np.mean(y_values)\n",
        "x_std, y_std = np.std(x_values), np.std(y_values)\n",
        "print(x_mean, x_std, y_mean, y_std)\n",
        "\n",
        "#density coloring\n",
        "xy = np.vstack([x_values, y_values])\n",
        "z = gaussian_kde(xy)(xy)\n",
        "\n",
        "plt.scatter(x_values, y_values, marker='x', c=z, cmap='plasma')\n",
        "plt.errorbar(x_mean, y_mean, xerr=x_std, yerr=y_std, fmt='o', color='red')\n",
        "\n",
        "# plt.colorbar()\n",
        "x = str(data[0][col_1])\n",
        "y = str(data[0][col_2])\n",
        "plt.xlabel(x)\n",
        "plt.ylabel(y)\n",
        "plt.title('Scatter plot')\n",
        "# plt.show()\n",
        "plt.savefig('/content/drive/My Drive/MFA/Plots/scatterplots2/' + x + ',' + y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'cat_columns_reordered' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m columns_to_plot \u001b[39m=\u001b[39m df[cat_columns_reordered]\n\u001b[1;32m      2\u001b[0m sns\u001b[39m.\u001b[39mset(style\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mticks\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m sns\u001b[39m.\u001b[39mpairplot(columns_to_plot, diag_kind\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mkde\u001b[39m\u001b[39m\"\u001b[39m, plot_kws\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39malpha\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m0.6\u001b[39m})\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cat_columns_reordered' is not defined"
          ]
        }
      ],
      "source": [
        "columns_to_plot = df[cat_columns_reordered]\n",
        "sns.set(style=\"ticks\")\n",
        "sns.pairplot(columns_to_plot, diag_kind=\"kde\", plot_kws={'alpha':0.6})\n",
        "plt.show()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Paired comparisons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pairplot for cat columns\n",
        "sns.pairplot(df[cat_columns])\n",
        "plt.savefig('/content/drive/MyDrive/MFA/pairplot'+''+'.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation heatmap for cat columns\n",
        "corr = df[cat_columns].corr()\n",
        "print(corr)\n",
        "print(corr.shape)\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm',center='0')\n",
        "plt.savefig('/content/drive/MyDrive/MFA/correlation_heatmap'+''+'.png',bbox_inches='tight')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Clustering Algorithms"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_O5HsTJ81mKd"
      },
      "source": [
        "## k-means clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# K-means Elbow chart\n",
        "inertia = []\n",
        "\n",
        "# Specify the range of 'k' values to test\n",
        "k_values = range(1, 11)\n",
        "\n",
        "# Perform clustering for each value of 'k'\n",
        "for k in k_values:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(df[cat_columns])\n",
        "    inertia.append(kmeans.inertia_)\n",
        "\n",
        "# Plot the elbow chart\n",
        "plt.plot(k_values, inertia, marker='o')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Sum of Squared Distances')\n",
        "plt.title('Elbow Chart')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dWqTklug12d",
        "outputId": "0cf32304-1ba0-4a69-a448-0c28e642a787"
      },
      "outputs": [],
      "source": [
        "# def k_cluster(n):\n",
        "\n",
        "# Select the columns you want to cluster and convert to numeric\n",
        "columns_to_cluster = cat_columns_reorder\n",
        "df[columns_to_cluster] = df[columns_to_cluster].apply(pd.to_numeric)\n",
        "\n",
        "# Perform KMeans clustering\n",
        "kmeans = KMeans(n_clusters=4)\n",
        "clusters = kmeans.fit_predict(df[columns_to_cluster])\n",
        "\n",
        "# Add the cluster labels to the dataframe\n",
        "df['cluster'] = clusters\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppg1xAOphBTW"
      },
      "outputs": [],
      "source": [
        "means = df.groupby('cluster')[columns_to_cluster].mean()\n",
        "stds = df.groupby('cluster')[columns_to_cluster].std()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gaussian Mixture"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Current clustering method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Assuming you have your data stored in the 'data' variable\n",
        "data = df[cat_columns_reorder]\n",
        "# Create the GMM object\n",
        "gmm = GaussianMixture(n_components=3)  # Specify the number of components/clusters\n",
        "\n",
        "# Fit the GMM model to the data\n",
        "gmm.fit(data)\n",
        "\n",
        "# Obtain the cluster labels assigned by GMM\n",
        "labels = gmm.predict(data)\n",
        "\n",
        "# Print the results\n",
        "print(labels)\n",
        "\n",
        "# Create a DataFrame to store the cluster labels\n",
        "cluster_df = pd.DataFrame(labels, columns=['cluster'])\n",
        "\n",
        "# Count the occurrences of each cluster label\n",
        "cluster_counts = cluster_df['cluster'].value_counts()\n",
        "\n",
        "# Sort the cluster counts in descending order\n",
        "cluster_counts_sorted = cluster_counts.sort_values(ascending=False)\n",
        "\n",
        "# Create a mapping dictionary for the new cluster labels\n",
        "cluster_mapping = {cluster_counts_sorted.index[i]: i for i in range(len(cluster_counts_sorted))}\n",
        "\n",
        "# Map the new cluster labels to the original DataFrame\n",
        "df['cluster'] = cluster_df['cluster'].map(cluster_mapping)\n",
        "\n",
        "# print\n",
        "cluster_counts = df['cluster'].value_counts()\n",
        "print(cluster_counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cluster_counts = df['cluster'].value_counts()\n",
        "print(cluster_counts)\n",
        "cluster_counts = df['cluster_reassigned'].value_counts()\n",
        "print(cluster_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Filter rows with cluster label '1'\n",
        "cluster_1_df = df[df['cluster'] == 0]\n",
        "\n",
        "# Step 2: Extract relevant features, if needed\n",
        "cluster_1_df = cluster_1_df[cat_columns_reorder]\n",
        "\n",
        "# Step 3: Apply clustering algorithm\n",
        "kmeans = KMeans(n_clusters=2)  # You can adjust the number of clusters as needed\n",
        "subcluster_labels = kmeans.fit_predict(cluster_1_df)\n",
        "\n",
        "# Map the subcluster labels from 0 and 1 to 3 and 4\n",
        "subcluster_labels_mapped = subcluster_labels + 3\n",
        "\n",
        "# Step 4: Assign subcluster labels back to the original DataFrame\n",
        "df.loc[df['cluster'] == 0, 'subcluster'] = subcluster_labels_mapped\n",
        "# Step 4: Assign subcluster labels back to the original DataFrame\n",
        "df.loc[df['cluster'] == 0, 'cluster_reassigned'] = subcluster_labels_mapped\n",
        "df.loc[df['cluster'] != 0, 'cluster_reassigned'] = df.loc[df['cluster'] != 0, 'cluster']\n",
        "\n",
        "# Print the updated DataFrame\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "cluster_counts = df['cluster_reassigned'].value_counts()\n",
        "print(cluster_counts)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cluster Demographics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "columns_to_plot=demographic_columns\n",
        "\n",
        "for column in columns_to_plot:\n",
        "    # Group the dataframe by the 'cluster' column and the current column\n",
        "    grouped = df.groupby([column, 'cluster_reassigned']).size().unstack()\n",
        "    \n",
        "    # Normalize so all bars are the same total length\n",
        "    grouped = grouped.div(grouped.sum(axis=1), axis=0)\n",
        "\n",
        "    # Plot the grouped data as a bar chart\n",
        "    grouped.plot(kind='barh', stacked=True)\n",
        "    \n",
        "    # Set the title and labels\n",
        "    plt.title(f'Bar Chart for {column} by Cluster')\n",
        "    plt.xlabel('Cluster')\n",
        "    plt.ylabel('Count')\n",
        "    \n",
        "    # Display the plot\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for cluster in df['cluster_reassigned'].unique():\n",
        "    # Filter the dataframe for the current cluster\n",
        "    cluster_df = df[df['cluster_reassigned'] == cluster]\n",
        "    \n",
        "    for column in columns_to_plot:\n",
        "        # Group the filtered dataframe by the current column\n",
        "        plt.figure()\n",
        "        grouped = cluster_df.groupby(column).size()\n",
        "        \n",
        "        # Plot the grouped data as a bar chart\n",
        "        grouped.plot(kind='bar', stacked=True)\n",
        "        \n",
        "        # Set the title and labels\n",
        "        plt.title(f'Bar Chart for {column} in Cluster {cluster}')\n",
        "        plt.xlabel('Count')\n",
        "        plt.ylabel(column)\n",
        "        \n",
        "        # Move the legend out of the way\n",
        "        # plt.ylim(0, 14000)\n",
        "\n",
        "        plt.legend().set_visible(False)\n",
        "        \n",
        "        # Display the plot\n",
        "        plt.savefig(f'230614/barcharts/{column} in Cluster {cluster}.png')\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bLpdQwDETsPI"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZrcpFLphJgb",
        "outputId": "d51ec57c-ee52-4813-98bc-e13e46eee9e0"
      },
      "outputs": [],
      "source": [
        "print(means)\n",
        "print(stds)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DPjUJl2ZfZwO"
      },
      "source": [
        "# Cluster characteristic graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import colorsys\n",
        "import numpy as np\n",
        "\n",
        "# Define the columns to plot\n",
        "columns_to_plot = cat_columns_reorder\n",
        "print(columns_to_plot)\n",
        "\n",
        "# Create the line chart\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Loop through each cluster and create a line chart\n",
        "count = 0\n",
        "clusters = df['cluster_reassigned'].unique()\n",
        "for cluster in clusters:\n",
        "    # Filter the dataframe to only include rows in the current cluster\n",
        "    subset = df[df['cluster_reassigned'] == cluster]\n",
        "\n",
        "    # Get the means and standard deviations for the subset\n",
        "    means = subset[columns_to_plot].mean()\n",
        "    stds = subset[columns_to_plot].std()\n",
        "    x = range(len(columns_to_plot))\n",
        "\n",
        "    # hue = count / len(clusters)\n",
        "    # count += 1\n",
        "    # color = colorsys.hsv_to_rgb(hue, 0.8, 0.8)\n",
        "\n",
        "    # Plot the means with error bars\n",
        "    ax.errorbar(x, means, marker='o', label='Cluster ' + str(cluster))\n",
        "\n",
        "mean = df[columns_to_plot].mean()\n",
        "\n",
        "# Add the overall means\n",
        "ax.errorbar(x, mean, marker='x', label='overall mean', color='gray', linestyle='dotted')\n",
        "\n",
        "# Set the x-axis ticks and labels\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(columns_to_plot, rotation=90)\n",
        "\n",
        "# Set the title and labels\n",
        "plt.title('Line Chart for Clusters')\n",
        "plt.xlabel('Columns')\n",
        "plt.ylabel('Mean')\n",
        "\n",
        "# Add a legend\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "# Display the plot\n",
        "# plt.savefig('230614/sanegraph.png',bbox='tight')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cNnyhtsF6wPJ"
      },
      "source": [
        "## Radar chart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmqesoAHiJgt"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display\n",
        "import pygal\n",
        "from pygal import Config\n",
        "from pygal.style import Style\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPDjHxZj28PO"
      },
      "outputs": [],
      "source": [
        "%pip install pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMLl_QJVYmPS"
      },
      "outputs": [],
      "source": [
        "import colorsys\n",
        "import pygal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGdgBbPAh5Wy"
      },
      "outputs": [],
      "source": [
        "# def radar_chart(columns_to_plot):\n",
        "\n",
        "# Define the columns to plot\n",
        "columns_to_plot = cat_columns_reorder\n",
        "print(columns_to_plot)\n",
        "\n",
        "\n",
        "# Create the radar chart\n",
        "chart = pygal.Radar(fill=False)\n",
        "chart.x_labels = columns_to_plot\n",
        "chart.range = [0,2]\n",
        "\n",
        "\n",
        "# Loop through each cluster and create a radar chart\n",
        "count = 0\n",
        "clusters = df['cluster'].unique()\n",
        "for cluster in clusters:\n",
        "    # Filter the dataframe to only include rows in the current cluster\n",
        "    subset = df[df['cluster'] == cluster]\n",
        "    \n",
        "    # Get the means for the subset\n",
        "    means = subset[columns_to_plot].mean()\n",
        "    # q1s = subset[columns_to_plot].quantile([0.25])\n",
        "    # print(means)\n",
        "\n",
        "    hue = count / len(clusters)\n",
        "    count += 1\n",
        "    color = colorsys.hsv_to_rgb(hue, 0.8, 0.8)\n",
        "    chart.add('Cluster ' + str(cluster), [round(mean, 2)+1 for mean in means], stroke_style={'width': 10, 'color': color})\n",
        "    # chart.add('Cluster ' + str(cluster), [round(q1, 2)+1 for q1 in q1s], stroke_style={'width': 10, 'color': color})\n",
        "    \n",
        "\n",
        "chart.render_to_file('Plots/spider4/'+'clusters_kmeans_' + str(len(clusters\n",
        "                                                                                       )) +'_' + str(cluster) + '.svg')\n",
        "\n",
        "\n",
        "    # chart_data = chart.render_to_png()\n",
        "    # display(SVG(chart.render()))\n",
        "    # Convert the PNG data to a base64-encoded string\n",
        "    # chart_data_base64 = base64.b64encode(chart_data).decode('utf-8')\n",
        "\n",
        "    # Display the chart as an HTML image\n",
        "    # display(HTML('<img src=\"data:image/png;base64,{0}\">'.format(chart_data_base64)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def radar_chart(columns_to_plot):\n",
        "\n",
        "# Define the columns to plot\n",
        "columns_to_plot = cat_columns_reorder\n",
        "print(columns_to_plot)\n",
        "\n",
        "\n",
        "# Loop through each cluster and create a radar chart\n",
        "count = 0\n",
        "clusters = df['cluster'].unique()\n",
        "for cluster in clusters:\n",
        "    # Filter the dataframe to only include rows in the current cluster\n",
        "    subset = df[df['cluster'] == cluster]\n",
        "\n",
        "    # Create the radar chart\n",
        "    chart = pygal.Radar(fill=False)\n",
        "    chart.x_labels = columns_to_plot\n",
        "    chart.range = [0,2.4]\n",
        "        \n",
        "    # Get the means for the subset\n",
        "    means = subset[columns_to_plot].mean()\n",
        "    stds = subset[columns_to_plot].std()\n",
        "    lowers = means-std\n",
        "    uppers = means + std\n",
        "\n",
        "    # hue = count / len(clusters)\n",
        "    # count += 1\n",
        "    # color = colorsys.hsv_to_rgb(hue, 0.8, 0.8)\n",
        "    chart.add('Cluster ' + str(cluster), [round(mean, 2)+1 for mean in means], stroke_style={'width': 10})\n",
        "    chart.add('Cluster -std' + str(cluster), [round(lower, 2)+1 for lower in lowers], stroke_style={'width': 10})\n",
        "    chart.add('Cluster +std' + str(cluster), [round(upper, 2)+1 for upper in uppers], stroke_style={'width': 10})\n",
        "    \n",
        "\n",
        "    chart.render_to_file('Plots/spider5/'+'clusters_kmeans_' +'_' + str(cluster) + '.svg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0A64iD105pr"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "Iss5VYJu3GP5",
        "outputId": "b330f961-63b4-4639-f2f3-729976717742"
      },
      "outputs": [],
      "source": [
        "# columns_to_cluster = cat_columns\n",
        "\n",
        "# pca = PCA(n_components=2)\n",
        "# pca_result = pca.fit_transform(df[columns_to_cluster])\n",
        "\n",
        "# print(\"Explained variance ratio 2:\", pca.explained_variance_ratio_)\n",
        "\n",
        "\n",
        "# # plt.scatter(pca_result[:,0], pca_result[:,1], c=df['cluster'], cmap='viridis')\n",
        "# # plt.xlabel('PC1')\n",
        "# # plt.ylabel('PC2')\n",
        "# # plt.title('PCA Plot of Clusters')\n",
        "# # plt.show()\n",
        "# n_components = 7\n",
        "# pca = PCA(n_components)\n",
        "# pca_result = pca.fit_transform(df[columns_to_cluster])\n",
        "\n",
        "# print(\"Explained variance ratio 3:\", pca.explained_variance_ratio_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "gW0Msqi1Pa_V",
        "outputId": "3255bd12-22b4-4b84-c0ba-bf2d463928ad"
      },
      "outputs": [],
      "source": [
        "loadings = []\n",
        "\n",
        "for i in range(n_components):\n",
        "\n",
        "  loading = pd.DataFrame(np.abs(pca.components_[i]))\n",
        "  loadings.append(loading)\n",
        "\n",
        "loadings = np.squeeze(loadings)\n",
        "# Print the loadings\n",
        "print(loadings)\n",
        "sns.heatmap(loadings, annot=True, yticklabels=['PC-'+str(x) for x in range(7)], cmap='coolwarm', center=0)\n",
        "# plt.show()\n",
        "plt.savefig('/Users/siaosilooi/Library/CloudStorage/GoogleDrive-looisiaosi@gmail.com/My Drive/MFA/loadings_heatmap_PCAcomponents'+''+'.png',bbox_inches='tight',)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APZMZ7AI8fyx",
        "outputId": "529d4b1f-6b84-4b1f-d946-804ce0b3e5ef"
      },
      "outputs": [],
      "source": [
        "# Correlation heatmap\n",
        "pca_df = pd.DataFrame(pca_result)\n",
        "# print(pca_df.head())\n",
        "# print(pca_df.info())\n",
        "# print(pca_df.describe())\n",
        "\n",
        "dfs=[]\n",
        "for i in range(6):\n",
        "  corrwith = pd.DataFrame(df[cat_columns]).corrwith(pca_df[i])\n",
        "  corr_df = pd.DataFrame(np.reshape(corrwith.values,(1,-1)),columns=corrwith.index)\n",
        "  dfs.append(corr_df)\n",
        "  \n",
        "corr = pd.concat(dfs, axis=0)\n",
        "print(corr)\n",
        "print(corr.shape)\n",
        "# corr.plot(kind='barh')\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "sns.heatmap(corr, annot=True, yticklabels=['PC-'+str(x) for x in range(6)],cmap='coolwarm')\n",
        "plt.show()\n",
        "# plt.savefig('/content/drive/MyDrive/MFA/correlation_heatmap_PCAcomponents'+''+'.png',bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2xpIvDX9B1d"
      },
      "outputs": [],
      "source": [
        "from kmodes.kmodes import KModes"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kEKBOfWfMbHA"
      },
      "source": [
        "*italicized text*# Autoencoding"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BcP0_t9YMe5N"
      },
      "source": [
        "# Autoencoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_D6V5MPPMdyd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faas7PnrGCvQ"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df2 = df[cat_columns_reorder]\n",
        "# Rescale the values in the 'cat_columns' column\n",
        "for i in cat_columns_reorder:\n",
        "  df2[i] = scaler.fit_transform(df[[i]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[cat_columns_reorder]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMDO5QN2MpbB",
        "outputId": "0805bdc8-f985-4d4c-aba0-8cdaf3089270"
      },
      "outputs": [],
      "source": [
        "df_cat = df2[cat_columns_reorder]\n",
        "\n",
        "input_dim = len(df_cat.columns)\n",
        "latent_dim = 1\n",
        "\n",
        "#create encoder\n",
        "encoder_inputs = keras.Input(shape=(input_dim,))\n",
        "x = layers.Dense(16, activation=\"relu\")(encoder_inputs)\n",
        "x = layers.Dense(32, activation=\"relu\")(x)\n",
        "latent = layers.Dense(latent_dim, activation=\"relu\")(x)\n",
        "\n",
        "encoder = keras.Model(encoder_inputs, latent, name=\"encoder\")\n",
        "\n",
        "#create decoder\n",
        "decoder_inputs = keras.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(16, activation=\"relu\")(decoder_inputs)\n",
        "x = layers.Dense(32, activation=\"relu\")(x)\n",
        "decoder_outputs = layers.Dense(input_dim, activation=\"sigmoid\")(x)\n",
        "\n",
        "decoder = keras.Model(decoder_inputs, decoder_outputs, name=\"decoder\")\n",
        "\n",
        "#create autoencoder\n",
        "autoencoder_inputs = keras.Input(shape=(input_dim,))\n",
        "latent = encoder(autoencoder_inputs)\n",
        "decoder_outputs = decoder(latent)\n",
        "autoencoder = keras.Model(autoencoder_inputs, decoder_outputs, name=\"autoencoder\")\n",
        "\n",
        "# Compile the model\n",
        "\n",
        "autoencoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
        "\n",
        "# Train the autoencoder\n",
        "autoencoder.fit(df_cat, df_cat, epochs=50, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Generate reconstructed data from test data\n",
        "reconstructed = autoencoder.predict(df_cat)\n",
        "\n",
        "#print\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "print('Original data:')\n",
        "print(df_cat.head())\n",
        "print('Reconstructed data:')\n",
        "print(pd.DataFrame(reconstructed, columns=df_cat.columns).head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVZF4-kvNIzq",
        "outputId": "396bdd3b-1204-4cb9-866b-b3c29ce0f4e9"
      },
      "outputs": [],
      "source": [
        "arr = encoder.predict(df_cat)\n",
        "print(arr)\n",
        "# df2[e  ncoded_values'] = arr\n",
        "# Get the highest value\n",
        "max_val = np.amax(arr)\n",
        "print(\"Highest value:\", max_val)\n",
        "\n",
        "# Get the lowest value \n",
        "\n",
        "min_val = np.amin(arr)\n",
        "print(\"Lowest value:\", min_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhUpmQfjMiaO",
        "outputId": "d957be3c-09d5-4ef2-dd01-00910b3828cb"
      },
      "outputs": [],
      "source": [
        "autoencoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3fbJoFyJzZu",
        "outputId": "3c64819d-e863-46c7-ff65-a4ce44fb6f47"
      },
      "outputs": [],
      "source": [
        "i = 5\n",
        "samples = np.array([[x/i for x in range(0,math.ceil(max_val)*i)]])\n",
        "print([x/i for x in range(0,math.ceil(max_val)*i)])\n",
        "samples = samples.T\n",
        "# print(samples)\n",
        "decoder_data = decoder.predict(samples)\n",
        "print(decoder_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "hbr7SDINQMuz",
        "outputId": "9908559a-80e2-4b01-857a-7db3a688b9e5"
      },
      "outputs": [],
      "source": [
        "data_t = decoder_data.T\n",
        "# print(data_t)\n",
        "plt.figure()\n",
        "\n",
        "for i in range(data_t.shape[0]):\n",
        "    plt.plot(samples,data_t[i])\n",
        "    \n",
        "\n",
        "plt.legend(cat_columns_reorder,bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.show()\n",
        "# plt.savefig()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Autoencoder plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assuming your dataset is in the same order as the encoder inputs\n",
        "encoder_inputs = df[cat_columns_reorder]  # Adjust this if necessary\n",
        "\n",
        "\n",
        "# Get the encoded output\n",
        "encoded_output = encoder.predict(encoder_inputs)\n",
        "# print(encoded_output)\n",
        "# print(encoded_output.T[0][1])\n",
        "\n",
        "# Add the encoded output to the DataFrame\n",
        "df['encoded_output'] = encoded_output.T[0]\n",
        "\n",
        "# Plotting\n",
        "plt.figure()\n",
        "\n",
        "# Iterate over unique clusters\n",
        "clusters = df['cluster'].unique()\n",
        "for cluster in clusters:\n",
        "    cluster_data = df[df['cluster'] == cluster]\n",
        "    print(1)\n",
        "    sns.histplot(data=cluster_data['encoded_output'], label=f'Cluster {cluster}')\n",
        "\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Encoded Output')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Density Plot of Clusters')\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assuming your DataFrame is named df\n",
        "cluster_counts = df['cluster'].value_counts()\n",
        "print(cluster_counts)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cluster plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "for i in cat_columns_reorder:\n",
        "    # Plotting\n",
        "    plt.figure()\n",
        "\n",
        "    # Iterate over unique clusters\n",
        "    clusters = df['cluster_reassigned'].unique()\n",
        "    for cluster in clusters:\n",
        "        cluster_data = df[df['cluster_reassigned'] == cluster]\n",
        "        sns.histplot(data=cluster_data[i], label=f'Cluster {cluster}', kde=False, bins=20)\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.xlabel(i)\n",
        "    plt.ylabel('Count')\n",
        "    plt.title('Count Plot of Clusters')\n",
        "\n",
        "    # Add legend\n",
        "    plt.legend()\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assuming your dataset is in the same order as the encoder inputs\n",
        "encoder_inputs = df[cat_columns_reorder]  # Adjust this if necessary\n",
        "\n",
        "# Get the encoded output\n",
        "encoded_output = encoder.predict(encoder_inputs)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot the density of the encoded output\n",
        "sns.histplot(data=encoded_output, fill=True)\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Encoded Output')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Density Plot of Encoded Output')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "hLEL_YHw-cBq",
        "_O5HsTJ81mKd",
        "cNnyhtsF6wPJ",
        "Xe0vpnP09EPe"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
